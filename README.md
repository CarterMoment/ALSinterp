# ALSinterp
Computer Vision Model that recognizes sign language letters with training capabilities built in using a 128-neuron neural network

HOW TO USE: 

If you would like to see the model in action, run "betterrunme.py"

If you would like to train the model to recognize new gestures, follow these steps:
1. Go to the script "gesturecollection.py" and find line 12.
2. Change the string to the name of the gesture you would like to train the model on.
3. Save, and run the script and show the computer that gesture with your hands.
4. Find the script "datapreprocessing.py" and press run.
5. Find the script "modeltraining.py" and press run. It may take a minute or so.
6. Now you are ready to use "betterrunme.py" with your new recognizable gesture!
